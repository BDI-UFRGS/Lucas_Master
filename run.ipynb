{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments \n",
    "<div style=\"text-align: right\"> Lucas Pugens Fernandes</div>\n",
    "\n",
    "This notebook is meant to execute clustering experiments according to the needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets\n",
    "Comment or uncomment lines according to which databases you want to test\n",
    "\n",
    "Each element from the list is composed by a tuple with:\n",
    "\n",
    "1. dataset identifier (string)\n",
    "2. dataset object (*according to the skit-learn format*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.datasets import thin_sections\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "\n",
    "datasets = []\n",
    "datasets.append(('thin_sections', thin_sections(reduced_data=True)))\n",
    "# datasets.append(('iris', load_iris()))\n",
    "# datasets.append(('breast_cancer', load_breast_cancer()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weightening\n",
    "\n",
    "Append new weightened datasets to the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "weights = [{'feature': 'Porosity', 'weight': 1000},\n",
    "           {'feature': 'Main/single size mode(mm):', 'weight': 1000}]\n",
    "\n",
    "weightened_thin_sections = copy.deepcopy(datasets[0][1])\n",
    "\n",
    "for weight in weights:\n",
    "    index_weight = datasets[0][1].feature_names.index(weight['feature'])\n",
    "\n",
    "    for i, point in enumerate(weightened_thin_sections.data):\n",
    "        weightened_thin_sections.data[i][index_weight] = point[index_weight] * weight['weight']\n",
    "    \n",
    "datasets.append(('wgth_thin_sections', weightened_thin_sections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading algorthms\n",
    "\n",
    "Comment or uncomment lines according to which algorithms you want to test.\n",
    "\n",
    "Each element from the list is composed by a tuple with:\n",
    "1. algorithm name identifier (string)\n",
    "2. algorithm constructor    \n",
    "3. key arguments to be used when calling the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pkg.clustering import Wlac\n",
    "from sklearn.cluster import DBSCAN, MiniBatchKMeans, SpectralClustering, AffinityPropagation, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from itertools import product\n",
    "\n",
    "algorithms = []\n",
    "# algorithms.append(('WLAC', Wlac, {}))\n",
    "# algorithms.append(('DBSCAN', DBSCAN, {})) PROBLEMS\n",
    "# algorithms.append(('KMeans', MiniBatchKMeans, {'n_clusters' : 10}))\n",
    "# algorithms.append(('SC', SpectralClustering, {'n_clusters' : 10}))\n",
    "# algorithms.append(('AP', AffinityPropagation, {}))\n",
    "\n",
    "# algorithms.append(('AC_complete_euc', AgglomerativeClustering, {'n_clusters' : 10, 'linkage': 'complete', 'affinity': 'euclidean'}))\n",
    "algorithms.append(('AC_complete_man', AgglomerativeClustering, {'n_clusters' : 10, 'linkage': 'complete', 'affinity': 'manhattan'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating scenarios\n",
    "Generates _N_ scenarios for each combination of algorithms and datasets into the _scenarios_ array, each with a different random initializer.\n",
    "\n",
    "Only **_random-dependent_** algorithms will be run _N_ times.\n",
    "\n",
    "Each scenario os composed by a tuple with:\n",
    "\n",
    "1. The dataset\n",
    "2. The algorithm\n",
    "3. The random seed initializer (**in the cases of _random-dependent_ algorithm**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from inspect import signature\n",
    "\n",
    "N = 1000\n",
    "\n",
    "random_algorithms = [algorithm for algorithm in algorithms if 'random_state' in str(signature(algorithm[1]))]\n",
    "predictable_algorithms = [algorithm for algorithm in algorithms if 'random_state' not in str(signature(algorithm[1]))]\n",
    "\n",
    "scenarios = list(product(datasets, random_algorithms, range(N)))\n",
    "scenarios += list(product(datasets, predictable_algorithms))\n",
    "\n",
    "del random_algorithms\n",
    "del predictable_algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel running\n",
    "The scenarios are mapped to a pool of threads running in parallel.\n",
    "\n",
    "The *CPU_USAGE* defines the percentage of available hardware threads to be used during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from pkg import track_job, execute_clustering\n",
    "from math import floor\n",
    "\n",
    "CPU_USAGE = 1\n",
    "\n",
    "cores = floor(cpu_count()*CPU_USAGE)\n",
    "p = Pool(cores)\n",
    "print(str(cores) + ' CORES')\n",
    "print('Starting clusters:')\n",
    "results = []\n",
    "job = p.map_async(execute_clustering, scenarios, callback=results.append, error_callback=lambda x: print(str(x)))\n",
    "track_job(job)\n",
    "results = results[0]\n",
    "print('Done clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results\n",
    "Plots are generated from the results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_score, completeness_score, fowlkes_mallows_score\n",
    "\n",
    "metrics = [{'label': 'Adjusted Rand score', 'func': adjusted_rand_score},\n",
    "           {'label': 'Adjusted mutual info score', 'func': adjusted_mutual_info_score},\n",
    "           {'label': 'Homogeneity score', 'func': homogeneity_score},\n",
    "           {'label': 'Completness score', 'func': completeness_score},\n",
    "           {'label': 'Fowlkes mallows score', 'func': fowlkes_mallows_score}]\n",
    "\n",
    "print(results[0]['algorithm_obj'].labels_)\n",
    "\n",
    "for metric in metrics:\n",
    "    for dataset_label, dataset_obj in datasets:\n",
    "        results_for_dataset = [result for result in results if result['dataset_label'] == dataset_label]\n",
    "\n",
    "        metric_by_algorithm = [[] for _ in algorithms]\n",
    "        for i, algorithm in enumerate(algorithms):\n",
    "            labeling_for_algorithm = [result['algorithm_obj'].labels_ for result in results_for_dataset if result['algorithm_label'] == algorithm[0]]\n",
    "            for labels in labeling_for_algorithm:\n",
    "                metric_by_algorithm[i].append((metric['func'](dataset_obj.target, labels)))\n",
    "            \n",
    "        \n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.boxplot(metric_by_algorithm,\n",
    "                        labels=[label for label, _, _ in algorithms],\n",
    "                        showmeans=True,\n",
    "                        meanline=True)\n",
    "        plt.title(dataset_label)\n",
    "        plt.ylabel(metric['label'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
