{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Thinsection Datasets From Multiple Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIRECTORY = '../datasets/MargemEquatorial/backup/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "from IPython.display import display\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering files from input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GATHERING FILES at ' + INPUT_DIRECTORY)\n",
    "csv_file_names = [\n",
    "    file_name for file_name in os.listdir(INPUT_DIRECTORY)\n",
    "    if isfile(join(INPUT_DIRECTORY, file_name))\n",
    "    and file_name.endswith('.csv')\n",
    "    and file_name != 'dataset.csv'\n",
    "]\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all CSV files and put generated DataFrames on a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('READING THIN SECTION FILES')\n",
    "csv_data_files = [\n",
    "    pd.read_csv(open(join(INPUT_DIRECTORY, csv_file_name)), index_col=0)\n",
    "    for csv_file_name in csv_file_names]\n",
    "dfs = []\n",
    "for csv in csv_data_files:\n",
    "    dfs.append(csv.applymap(partial(pd.to_numeric, errors='ignore')))\n",
    "csv_data_files = dfs\n",
    "\n",
    "for csv in csv_data_files:\n",
    "    features = csv.index.values\n",
    "    processed_features = []\n",
    "    for feature in features:\n",
    "        n_attributes = feature.count(' - ') +1\n",
    "        if n_attributes == 3:\n",
    "            processed_features.append('[primary]'+feature)\n",
    "        elif n_attributes == 7:\n",
    "            processed_features.append('[diagenetic]'+feature)\n",
    "        elif n_attributes == 6:\n",
    "            processed_features.append('[porosity]'+feature)\n",
    "        else:\n",
    "            processed_features.append(feature)\n",
    "            \n",
    "    csv.index = processed_features\n",
    "\n",
    "    \n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated features\n",
    "Should have no output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DUPLICATES:')\n",
    "df_list = []\n",
    "for df, file_name in zip(csv_data_files, csv_file_names):\n",
    "    print(file_name)\n",
    "    for index in df.index.values:\n",
    "        if df.index.values.tolist().count(index) > 1:\n",
    "            df_list.append(index)\n",
    "            print('\\t'+str(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function defined to find if a given string contains numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_files = [df[df.apply(lambda x: x.name == 'petrofacie' or x.apply(is_number), axis=1)] for df in csv_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in csv_data_files:\n",
    "#     with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#         display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_files = [df.dropna(axis=0, how='any') for df in csv_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_files = [df.groupby(df.index).sum() for df in csv_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in csv_data_files:\n",
    "#     with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#         display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge DataFrames cohesively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(df.shape[0] for df in csv_data_files))\n",
    "print(sum(df.shape[1] for df in csv_data_files))\n",
    "print('MERGING DATA')\n",
    "full_csv = pd.DataFrame()\n",
    "\n",
    "full_csv = pd.concat(csv_data_files, axis=1)\n",
    "full_csv = full_csv.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display merged DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "# display(full_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate unused features\n",
    "- Non-numeric features (except petrofacies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose dataset\n",
    "Turns a file from the format instances by columns to instances by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_csv = full_csv.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(full_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves merged DataFrame as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# csv_file = open(join(INPUT_DIRECTORY, 'dataset.csv'), \"w\")\n",
    "# csv_file.write(full_csv.csv)\n",
    "# csv_file.close()\n",
    "full_csv.to_csv(join(INPUT_DIRECTORY, 'dataset.csv'), encoding='utf-8', quoting=csv.QUOTE_NONNUMERIC, float_format='%.10f')\n",
    "\n",
    "print('DONE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
