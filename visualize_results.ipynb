{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_utils import main\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from package.orm_models import local_create_session, Result\n",
    "from itertools import groupby\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from package.orm_models import Result\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_show_results(args):\n",
    "    pass\n",
    "    sns.heatmap(main(args+['--confusion-matrix']), annot=True, fmt='.0f')\n",
    "    plt.show()\n",
    "    main(args+['--plot-correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = 'grouping.db'\n",
    "default_args = [\n",
    "    '--db-file', DATABASE,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = local_create_session(DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = session.query(Result).all()\n",
    "group_results = groupby(results, key=lambda x: list(map(str, x.args)))\n",
    "\n",
    "results_df = []\n",
    "results_df_indexes = []\n",
    "results_df_columns = []\n",
    "# selection_writter = pd.ExcelWriter('selected_columns.xlsx')\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "    for key, group in group_results:\n",
    "        results = list(group)\n",
    "        result = results[0]\n",
    "        adj_rand = float(result.adjusted_rand_score)\n",
    "        experiment_name = 'UNKNOWN'\n",
    "        scenario = ''\n",
    "        for arg in key:\n",
    "            print(f'{arg}')\n",
    "            if str(arg).startswith('experiment_name'):\n",
    "                experiment_name = str(arg)[17:]\n",
    "            elif str(arg).startswith('scenario'):\n",
    "                scenario = str(arg)[10:]\n",
    "        selected_features = []\n",
    "        accuracies = []\n",
    "        aris = []\n",
    "        f_measures = []\n",
    "        for result in results:\n",
    "            accuracies += [result.accuracy]\n",
    "            aris += [result.adjusted_rand_score]\n",
    "            f_measures += [result.f_measure]\n",
    "            print(f'\\tAccuracy: {result.accuracy}')\n",
    "            print(f'\\tARI: {result.adjusted_rand_score}')\n",
    "            print(f'\\tF-Measure: {result.f_measure}')\n",
    "            selected_features += result.selected_features\n",
    "        print(f'Accuracy: {np.average(accuracies)} ± {np.std(accuracies)}')\n",
    "        print(f'ARI: {np.average(aris)} ± {np.std(aris)}')\n",
    "        print(f'F-Measure: {np.average(f_measures)} ± {np.std(f_measures)}')\n",
    "        print(f'Selected features: {len(result.selected_features)}')\n",
    "        selected_features = [feature.column for feature in selected_features]\n",
    "        selected_features = dict(Counter(selected_features))\n",
    "        selected_features = pd.DataFrame.from_dict(selected_features, orient='index', columns=['count'])\n",
    "        selected_features = selected_features.sort_values(by='count', ascending=False)\n",
    "#         display(selected_features)\n",
    "#         selected_features.to_excel(selection_writter, experiment_name)\n",
    "        results_df += [[np.average(accuracies), np.std(accuracies),\n",
    "                       np.average(aris), np.std(aris),\n",
    "                       np.average(f_measures), np.std(f_measures)]]\n",
    "        results_df_indexes += [(experiment_name, scenario)]\n",
    "\n",
    "        args = default_args + ['--id'] + [str(result.id) for result in results]\n",
    "        std_show_results(args)\n",
    "        print('-------------------------------------------------------------------------------------')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "# selection_writter.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results_df_indexes)\n",
    "# print(results_df_columns)\n",
    "# print(results_df)\n",
    "from itertools import product\n",
    "index = pd.MultiIndex.from_tuples(results_df_indexes, names=['dataset', 'scenario'])\n",
    "columns = pd.MultiIndex.from_tuples(product(['Accuracy', 'ARI', 'F-Measure'], ['average', 'std']))\n",
    "print(columns)\n",
    "df = pd.DataFrame(results_df, index=results_df_indexes, columns=columns).sort_index()\n",
    "df.index = pd.MultiIndex.from_tuples(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('resultados.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
